# @dreamer/webrtc 大规模架构性能分析

## 📊 目录

1. [当前架构分析](#当前架构分析)
2. [性能瓶颈分析](#性能瓶颈分析)
3. [大规模架构设计](#大规模架构设计)
4. [库升级路径](#库升级路径)
5. [服务器配置方案](#服务器配置方案)
6. [性能优化建议](#性能优化建议)

---

## 一、当前架构分析

### 1.1 当前实现架构

**Mesh 架构（点对点）**：
```
客户端 A ←→ 客户端 B
    ↕         ↕
客户端 C ←→ 客户端 D
```

**特点**：
- 每个客户端与其他所有客户端建立直接 P2P 连接
- 媒体流在客户端之间直接传输，不经过服务器
- 信令服务器只负责连接建立和协商（SDP、ICE candidates）

**代码实现**：
- `RTCClient` 使用 `peerConnections: Map<string, RTCPeerConnection>` 管理多个连接
- 每个用户对应一个 `RTCPeerConnection`
- 信令服务器 `SignalingServer` 只处理信令消息转发

### 1.2 连接数量计算

**重要说明**：
- **"10 人"指的是单个房间内同时通话的人数**，不是服务器的并发连接数
- **信令服务器可以支持数千个并发连接**（每个连接对应一个客户端）
- **限制在于客户端**：每个客户端需要与其他客户端建立 P2P 连接
- **媒体流是点对点的**：不经过服务器，直接在客户端之间传输

**Mesh 架构连接数**：
- N 个用户的房间 = N × (N-1) / 2 个 P2P 连接（客户端之间）
- 每个客户端需要维护 (N-1) 个 RTCPeerConnection
- 信令服务器连接数 = N 个 Socket.IO 连接（每个客户端 1 个）

| 房间内用户数 | 总 P2P 连接数 | 每个客户端连接数 | 信令服务器连接数 | 上行带宽倍数 | 下行带宽倍数 |
|------------|-------------|-----------------|----------------|-------------|-------------|
| 2 | 1 | 1 | 2 | 1x | 1x |
| 5 | 10 | 4 | 5 | 4x | 4x |
| 10 | 45 | 9 | 10 | 9x | 9x |
| 20 | 190 | 19 | 20 | 19x | 19x |
| 50 | 1,225 | 49 | 50 | 49x | 49x |
| 100 | 4,950 | 99 | 100 | 99x | 99x |

**示例场景**：
- 100 个房间，每个房间 5 人 = 500 个信令服务器连接（服务器可以轻松处理）
- 但每个房间内的客户端需要维护 4 个 P2P 连接（客户端负担重）
- 1 个房间，100 人 = 100 个信令服务器连接（服务器可以轻松处理）
- 但每个客户端需要维护 99 个 P2P 连接（客户端无法承受）

### 1.3 当前架构的优势

✅ **优点**：
- 实现简单，无需媒体服务器
- 延迟低（P2P 直连，媒体流不经过服务器）
- **信令服务器负载低**：只处理信令，可以支持数千个并发连接
- **媒体流不经过服务器**：节省服务器带宽和 CPU
- 适合小规模场景（单个房间 < 10 人）

❌ **缺点**：
- **客户端连接数随房间人数线性增长**：每个客户端需要维护 (N-1) 个连接
- **客户端带宽消耗大**：需要接收 (N-1) 个媒体流
- **客户端 CPU 消耗大**：需要处理 (N-1) 个连接的编解码
- **不适合大规模房间**：单个房间 > 10 人时，客户端性能成为瓶颈

---

## 二、性能瓶颈分析

### 2.1 客户端性能瓶颈（主要瓶颈）

**重要**：Mesh 架构的瓶颈在**客户端**，不在服务器！

**带宽瓶颈**：
```
假设每个用户发送 1 Mbps 的视频流：
- 10 人房间：每个客户端需要接收 9 Mbps（9 个流）
- 50 人房间：每个客户端需要接收 49 Mbps（49 个流）
- 100 人房间：每个客户端需要接收 99 Mbps（99 个流）

注意：这些媒体流是点对点的，不经过服务器！
```

**CPU 瓶颈**：
- 每个 RTCPeerConnection 需要 CPU 资源处理编解码
- 多个连接并发处理，CPU 负载线性增长
- 浏览器端 CPU 资源有限（通常 2-4 核）

**内存瓶颈**：
- 每个连接需要维护状态和缓冲区
- 连接数增长，内存消耗线性增长
- 浏览器端内存有限（通常 4-8 GB）

**连接数瓶颈**：
- 浏览器对同时建立的 WebRTC 连接数有限制
- 通常浏览器最多支持 50-100 个并发连接
- 但实际使用中，10 个以上连接就会导致性能问题

### 2.2 服务器性能瓶颈（不是主要瓶颈）

**信令服务器（当前实现）**：
- ✅ **Socket.IO 连接数**：可以支持 5,000-10,000 个并发连接
- ✅ **信令消息处理**：轻量级，性能良好（每条消息 < 1 KB）
- ✅ **服务器负载**：非常低（只处理信令，不处理媒体流）
- ✅ **可以支持大量房间**：100 个房间 × 10 人 = 1,000 个连接（轻松处理）
- ❌ **无法解决的问题**：客户端需要维护的 P2P 连接数（这是客户端瓶颈）

**媒体服务器（需要新增）**：
- 需要处理 RTP 媒体流的接收、转发、混合
- CPU 和带宽消耗大
- 需要专门的服务器实现

### 2.3 网络瓶颈

**Mesh 架构网络问题**：
- 每个客户端需要与所有其他客户端建立 P2P 连接
- NAT 穿透问题：需要 STUN/TURN 服务器（但 TURN 服务器只是中继，不处理媒体）
- 网络延迟：多个跳转，延迟累积
- **注意**：媒体流是点对点的，不经过信令服务器

### 2.4 关键区别总结

| 项目 | 信令服务器 | 客户端（Mesh 架构） |
|------|----------|-------------------|
| **连接数限制** | 5,000-10,000 个 Socket.IO 连接 | 每个客户端 (N-1) 个 RTCPeerConnection |
| **可以支持的房间数** | 数百个房间 | 取决于每个房间的人数 |
| **可以支持的总用户数** | 数千个用户 | 单个房间 < 10 人 |
| **瓶颈位置** | 不是瓶颈 | **是主要瓶颈** |
| **媒体流处理** | 不处理（只处理信令） | 点对点传输，不经过服务器 |
| **带宽消耗** | 低（每条信令 < 1 KB） | 高（需要接收多个流） |
| **CPU 消耗** | 低（只处理信令消息） | 高（需要处理多个连接的编解码） |

**结论**：
- ✅ **信令服务器可以支持大规模并发**（数千个连接）
- ✅ **可以支持大量房间**（只要每个房间人数不多）
- ❌ **单个房间人数受限**（> 10 人时客户端成为瓶颈）
- ❌ **媒体流是点对点的**，服务器无法帮助减轻客户端负担

---

## 三、大规模架构设计

### 3.1 SFU 架构（推荐）

**Selective Forwarding Unit（选择性转发单元）**

#### 3.1.1 SFU 工作原理

**架构图**：
```
客户端 A ──┐
           │ 媒体流（上行）
客户端 B ──┼──► SFU 媒体服务器 ◄── 客户端 C
           │    (接收+转发)          │
客户端 D ──┘                        │
           │ 媒体流（下行）          │
客户端 E ──────────────────────────┘
```

**详细工作流程**：

1. **连接建立阶段**：
   ```
   客户端 A → 信令服务器 → 客户端 A 获取 SFU 服务器地址
   客户端 A → SFU 服务器 → 建立 RTCPeerConnection（Transport）
   ```

2. **媒体流发布阶段**：
   ```
   客户端 A 获取本地媒体流（getUserMedia）
   客户端 A → SFU 服务器 → 发布媒体流（publish）
   SFU 服务器接收并存储客户端 A 的媒体流
   ```

3. **媒体流订阅阶段**：
   ```
   客户端 B 加入房间
   客户端 B → SFU 服务器 → 订阅客户端 A 的媒体流（subscribe）
   SFU 服务器 → 客户端 B → 转发客户端 A 的媒体流
   ```

4. **选择性转发**：
   ```
   - 客户端 B 可以只订阅客户端 A 的流（不订阅 C、D）
   - 客户端 C 可以订阅 A 和 B 的流（不订阅 D）
   - SFU 服务器根据订阅关系选择性转发
   ```

**关键技术点**：

1. **RTP 包转发**：
   - SFU 服务器接收 RTP 包（不解码）
   - 根据订阅关系，将 RTP 包转发给订阅者
   - 不解码、不编码，只是转发（性能高）

2. **Simulcast（联播）**：
   - 客户端可以发送多个分辨率的流（低、中、高）
   - SFU 服务器转发不同分辨率的流给不同订阅者
   - 根据订阅者的网络状况选择合适的分辨率

3. **SVC（可扩展视频编码）**：
   - 客户端发送一个可扩展的编码流
   - SFU 服务器可以提取不同层级的流
   - 根据订阅者需求转发不同层级的流

4. **动态订阅**：
   - 客户端可以动态订阅/取消订阅某个流
   - 客户端可以只订阅音频，不订阅视频
   - 客户端可以只订阅屏幕共享，不订阅摄像头

#### 3.1.2 SFU 房间容量

**单 SFU 服务器容量**：

| 服务器配置 | 并发用户数 | 房间数（每房间 50 人） | 说明 |
|-----------|-----------|---------------------|------|
| **低配**（4 核 CPU，8 GB 内存，1 Gbps） | 500-800 人 | 10-16 个房间 | 适合中小规模 |
| **中配**（8 核 CPU，16 GB 内存，10 Gbps） | 1,000-2,000 人 | 20-40 个房间 | 适合中大规模 |
| **高配**（16 核 CPU，32 GB 内存，10 Gbps） | 2,000-5,000 人 | 40-100 个房间 | 适合大规模 |
| **集群**（多台服务器） | 10,000+ 人 | 200+ 个房间 | 适合超大规模 |

**单个房间容量**：

| 房间人数 | 客户端连接数 | 服务器连接数 | 服务器负载 | 可行性 |
|---------|------------|------------|-----------|--------|
| 10 人 | 每个客户端 1 个 | 10 个 | 低 | ✅ 完全可行 |
| 50 人 | 每个客户端 1 个 | 50 个 | 中 | ✅ 完全可行 |
| 100 人 | 每个客户端 1 个 | 100 个 | 中 | ✅ 完全可行 |
| 500 人 | 每个客户端 1 个 | 500 个 | 高 | ✅ 可行（需要高配服务器） |
| 1,000 人 | 每个客户端 1 个 | 1,000 个 | 很高 | ⚠️ 需要集群或高配服务器 |
| 5,000 人 | 每个客户端 1 个 | 5,000 个 | 极高 | ⚠️ 需要集群部署 |

**关键限制因素**：

1. **服务器带宽**：
   ```
   假设每个用户发送 1 Mbps 的视频流：
   - 100 人房间：服务器需要接收 100 Mbps（上行）
   - 100 人房间：如果每人订阅 10 个流，服务器需要转发 1,000 Mbps（下行）
   - 总带宽需求：1,100 Mbps ≈ 1.1 Gbps
   ```

2. **服务器 CPU**：
   - RTP 包转发需要 CPU 处理
   - 每个连接需要维护状态
   - 拥塞控制、带宽估计等需要 CPU

3. **服务器内存**：
   - 每个连接需要维护缓冲区
   - 每个连接约 5-10 MB 内存
   - 1,000 个连接 ≈ 5-10 GB 内存

4. **网络延迟**：
   - SFU 服务器作为中继，增加一跳延迟
   - 通常增加 10-50ms 延迟
   - 仍然比 MCU 延迟低

#### 3.1.3 SFU vs Mesh 对比

| 指标 | Mesh 架构 | SFU 架构 |
|------|----------|---------|
| **单个房间最大人数** | 10-20 人 | 100-1,000+ 人 |
| **客户端连接数** | (N-1) 个 | 1 个 |
| **客户端带宽（下行）** | (N-1) × 流大小 | 可控制（只订阅需要的流） |
| **服务器连接数** | N 个（信令） | N 个（媒体） |
| **服务器带宽** | 低（只处理信令） | 高（需要转发媒体流） |
| **服务器 CPU** | 低 | 中 |
| **延迟** | 最低（P2P 直连） | 低（增加一跳） |
| **灵活性** | 低（必须接收所有流） | 高（可以选择性订阅） |

**性能优势**：
- ✅ **连接数**：N 个用户 = N 个连接（每个客户端 1 个连接）
- ✅ **客户端带宽**：上行 1x，下行可控制（只订阅需要的流）
- ✅ **服务器负载**：只转发 RTP 包，不解码/编码，负载相对较低
- ✅ **可扩展性**：可以通过集群部署支持更大规模

**适用场景**：
- ✅ 大规模多人通话（10-1000+ 人）
- ✅ 需要低延迟的场景
- ✅ 客户端性能较好的场景
- ✅ 需要灵活订阅的场景（如只订阅音频、只订阅屏幕共享）

### 3.2 MCU 架构

**Multipoint Control Unit（多点控制单元）**

**架构图**：
```
客户端 A ──┐
           │
客户端 B ──┼──► MCU 媒体服务器 ◄── 客户端 C
           │    (解码+混合+编码)      │
客户端 D ──┘                        │
                                    │
客户端 E ──────────────────────────┘
```

**工作原理**：
1. 每个客户端只与 MCU 服务器建立连接
2. MCU 服务器接收所有客户端的媒体流
3. 服务器解码所有流，混合音频和视频
4. 服务器重新编码，发送一个混合流给每个客户端

**性能优势**：
- 连接数：N 个用户 = N 个连接
- 客户端带宽：上行 1x，下行 1x（只接收一个混合流）
- 客户端 CPU：只需要解码一个流

**性能劣势**：
- 服务器负载：非常高（解码 + 混合 + 编码）
- 延迟：较高（混合和编码需要时间）
- 灵活性：较低（客户端无法选择查看哪个流）

**适用场景**：
- ✅ 客户端性能差的场景
- ✅ 客户端带宽受限的场景
- ✅ 广播型会议（webinar）
- ❌ 不适合实时交互强的场景

### 3.3 混合架构

**Mesh + SFU 混合**：
- 小规模（< 10 人）：使用 Mesh 架构
- 大规模（> 10 人）：自动切换到 SFU 架构

**架构图**：
```
小规模（Mesh）：
客户端 A ←→ 客户端 B
    ↕         ↕
客户端 C ←→ 客户端 D

大规模（SFU）：
客户端 A ──┐
客户端 B ──┼──► SFU 服务器
客户端 C ──┤
客户端 D ──┘
```

---

## 四、库升级路径

### 4.1 架构升级方案

#### 方案 A：保持向后兼容，添加 SFU 支持

**设计思路**：
- 保持现有的 Mesh 架构不变
- 添加 SFU 模式作为可选功能
- 通过配置选项切换架构模式

**实现步骤**：

1. **扩展 RTCClient 配置**：
```typescript
interface RTCClientOptions {
  // ... 现有配置
  architecture?: 'mesh' | 'sfu' | 'auto'; // 新增：架构模式
  sfuUrl?: string; // SFU 服务器地址
  sfuApiKey?: string; // SFU 服务器认证密钥
}
```

2. **添加 SFU 客户端适配器**：
```typescript
class SFUClientAdapter {
  private sfuConnection: RTCPeerConnection;
  private publishedTracks: Map<string, RTCRtpSender> = new Map();
  private subscribedTracks: Map<string, RTCRtpReceiver> = new Map();

  // 发布媒体流到 SFU
  async publishTrack(track: MediaStreamTrack): Promise<void>;

  // 订阅其他用户的媒体流
  async subscribeTrack(userId: string, trackId: string): Promise<MediaStreamTrack>;

  // 取消订阅
  async unsubscribeTrack(trackId: string): Promise<void>;
}
```

3. **修改 RTCClient 实现**：
```typescript
class RTCClient {
  private architecture: 'mesh' | 'sfu' | 'auto';
  private sfuAdapter?: SFUClientAdapter;

  async joinRoom(roomId: string, userId?: string): Promise<void> {
    // 根据架构模式选择实现
    if (this.architecture === 'sfu' ||
        (this.architecture === 'auto' && this.shouldUseSFU(roomId))) {
      await this.joinRoomSFU(roomId, userId);
    } else {
      await this.joinRoomMesh(roomId, userId);
    }
  }

  private shouldUseSFU(roomId: string): boolean {
    // 根据房间人数自动选择
    const roomInfo = this.getRoomInfo(roomId);
    return roomInfo?.users.length > 10;
  }
}
```

#### 方案 B：添加 SFU 服务器实现

**设计思路**：
- 在 Deno/Bun 环境中实现 SFU 服务器
- 使用 WebRTC 服务器端库（如 Pion WebRTC 的绑定）

**实现步骤**：

1. **创建 SFU 服务器类**：
```typescript
class SFUServer {
  private rooms: Map<string, SFURoom> = new Map();
  private transports: Map<string, WebRTCTransport> = new Map();

  // 处理客户端连接
  async handleTransport(transportId: string, offer: RTCSessionDescriptionInit): Promise<RTCSessionDescriptionInit>;

  // 处理媒体流发布
  async publishTrack(transportId: string, track: MediaStreamTrack): Promise<string>;

  // 处理媒体流订阅
  async subscribeTrack(transportId: string, trackId: string): Promise<MediaStreamTrack>;
}
```

2. **集成到信令服务器**：
```typescript
class SignalingServer {
  private sfuServer?: SFUServer;

  constructor(options: SignalingServerOptions) {
    // ... 现有代码
    if (options.enableSFU) {
      this.sfuServer = new SFUServer(options.sfuOptions);
    }
  }

  private handleSignaling(socket: SocketIOSocket, message: SignalingMessage): void {
    if (message.type === 'sfu-transport') {
      // 处理 SFU 传输
      this.handleSFUTransport(socket, message);
    } else {
      // 处理 Mesh 信令
      this.handleMeshSignaling(socket, message);
    }
  }
}
```

### 4.2 技术选型

#### 选项 1：使用现有媒体服务器（推荐）

**Mediasoup**：
- ✅ 成熟的 Node.js SFU 实现
- ✅ 支持 Deno/Bun（通过 Node.js 兼容层）
- ✅ 性能优秀，支持大规模并发
- ❌ 需要 Node.js 环境或兼容层

**Janus**：
- ✅ C 语言实现，性能极高
- ✅ 支持多种架构（SFU、MCU、录制）
- ❌ 需要 C 绑定或 HTTP API 调用

**Kurento**：
- ✅ Java 实现，功能完整
- ✅ 支持 SFU 和 MCU
- ❌ 资源消耗大

#### 选项 2：自研 SFU 实现

**技术栈**：
- **Deno/Bun**：使用 WebAssembly 或 FFI 调用 C/C++ 库
- **Pion WebRTC**：Go 语言实现，可以通过 FFI 调用
- **libwebrtc**：Google 的 WebRTC 库，C++ 实现

**实现难度**：
- SFU：中等难度（主要是 RTP 转发）
- MCU：高难度（需要编码/解码）

### 4.3 升级路径建议

**阶段 1：保持兼容，添加 SFU 客户端支持**
- 时间：1-2 周
- 工作：添加 SFU 客户端适配器，支持连接外部 SFU 服务器
- 影响：向后兼容，不影响现有功能

**阶段 2：集成现有媒体服务器**
- 时间：2-4 周
- 工作：集成 Mediasoup 或 Janus，提供统一的 API
- 影响：需要额外的服务器部署

**阶段 3：自研 SFU 实现（可选）**
- 时间：2-3 个月
- 工作：使用 WebAssembly 或 FFI 实现 SFU 服务器
- 影响：完全自主可控，但开发成本高

---

## 五、服务器配置方案

### 5.1 信令服务器配置

**当前信令服务器（SignalingServer）**：

**单机配置**：
```typescript
const server = new SignalingServer({
  port: 3000,
  host: '0.0.0.0',
  // 可以处理数千个 Socket.IO 连接
});
```

**性能指标**：
- 连接数：5,000 - 10,000 个 Socket.IO 连接
- CPU：低（只处理信令消息）
- 内存：每个连接约 10-20 KB
- 带宽：每个连接约 1-5 Kbps（信令流量）

**集群配置**：
```typescript
// 使用 Redis 作为消息总线
const server1 = new SignalingServer({
  port: 3000,
  redis: { host: 'redis-server', port: 6379 },
});

const server2 = new SignalingServer({
  port: 3001,
  redis: { host: 'redis-server', port: 6379 },
});
```

**负载均衡**：
- 使用 Nginx/HAProxy 进行负载均衡
- 使用 Redis Pub/Sub 进行服务器间消息同步

### 5.2 SFU 媒体服务器配置

#### 方案 A：使用 Mediasoup

**服务器配置**：
```typescript
import { createWorker } from 'mediasoup';

const worker = await createWorker({
  logLevel: 'warn',
  rtcMinPort: 40000,
  rtcMaxPort: 49999,
});

const router = await worker.createRouter({
  mediaCodecs: [
    {
      kind: 'audio',
      mimeType: 'audio/opus',
      clockRate: 48000,
      channels: 2,
    },
    {
      kind: 'video',
      mimeType: 'video/VP8',
      clockRate: 90000,
    },
  ],
});
```

**性能指标**：
- 单机支持：500-1000 个并发用户
- CPU：中等（RTP 转发）
- 内存：每个用户约 5-10 MB
- 带宽：每个用户上行 1-2 Mbps，下行 1-2 Mbps × 订阅数

**服务器规格建议**：
- CPU：4-8 核
- 内存：8-16 GB
- 带宽：1 Gbps（支持 500 用户）
- 网络：低延迟（< 50ms）

#### 方案 B：使用 Janus

**服务器配置**：
```bash
# Janus 配置文件
[general]
configs_folder = /etc/janus
plugins_folder = /usr/lib/janus/plugins
transports_folder = /usr/lib/janus/transports
events_folder = /usr/lib/janus/events
```

**性能指标**：
- 单机支持：1000-2000 个并发用户
- CPU：中等（C 语言实现，性能优秀）
- 内存：每个用户约 3-5 MB
- 带宽：与 Mediasoup 类似

**服务器规格建议**：
- CPU：8-16 核
- 内存：16-32 GB
- 带宽：10 Gbps（支持 1000 用户）
- 网络：低延迟（< 50ms）

### 5.3 MCU 媒体服务器配置

**服务器配置**：
```typescript
// MCU 需要更强的服务器
const mcuServer = new MCUServer({
  maxParticipants: 100,
  videoCodec: 'VP8',
  audioCodec: 'OPUS',
  videoResolution: '1280x720',
  videoFPS: 30,
});
```

**性能指标**：
- 单机支持：50-100 个并发用户（受 CPU 限制）
- CPU：非常高（解码 + 混合 + 编码）
- 内存：每个用户约 50-100 MB
- 带宽：每个用户上行 1-2 Mbps，下行 1-2 Mbps

**服务器规格建议**：
- CPU：16-32 核（推荐使用 GPU 加速）
- 内存：32-64 GB
- 带宽：1 Gbps（支持 100 用户）
- GPU：可选，用于视频编码加速

### 5.4 混合架构服务器配置

**架构设计**：
```
┌─────────────────┐
│  负载均衡器      │
│  (Nginx/HAProxy) │
└────────┬────────┘
         │
    ┌────┴────┐
    │         │
┌───▼───┐  ┌──▼───┐
│信令服务器│  │信令服务器│
│  (x2)  │  │  (x2)  │
└───┬───┘  └──┬───┘
    │         │
    └────┬────┘
         │
    ┌────▼────┐
    │  Redis  │
    │ (消息总线)│
    └─────────┘
         │
    ┌────▼────┐
    │         │
┌───▼───┐  ┌──▼───┐
│SFU服务器│  │SFU服务器│
│  (x3)  │  │  (x3)  │
└────────┘  └────────┘
```

**服务器配置示例**：

**信令服务器集群**：
- 服务器数量：2-4 台
- 每台配置：2 核 CPU，4 GB 内存
- 总容量：10,000-20,000 个连接

**SFU 服务器集群**：
- 服务器数量：3-6 台
- 每台配置：8 核 CPU，16 GB 内存，1 Gbps 带宽
- 总容量：1,500-3,000 个并发用户

**Redis 服务器**：
- 服务器数量：1-2 台（主从）
- 配置：4 核 CPU，8 GB 内存
- 用途：消息总线、房间状态同步

---

## 六、性能优化建议

### 6.1 客户端优化

**连接池优化**：
- ✅ 已实现：`RTCPeerConnectionPool` 连接池
- 建议：根据房间人数动态调整连接池大小

**带宽优化**：
- 使用 Simulcast：发送多个分辨率的流，客户端按需订阅
- 使用 SVC（可扩展视频编码）：动态调整视频质量
- 音频优先：在带宽受限时优先保证音频质量

**CPU 优化**：
- 硬件加速：使用 GPU 进行视频编码
- 降低分辨率：根据网络状况自动调整
- 帧率控制：降低帧率减少 CPU 消耗

### 6.2 服务器优化

**信令服务器优化**：
- ✅ 已实现：批量消息处理
- 建议：使用 Redis 进行水平扩展
- 建议：使用消息队列（如 RabbitMQ）处理高并发

**SFU 服务器优化**：
- 使用 Simulcast：服务器转发多个分辨率的流
- 动态订阅：客户端只订阅需要的流
- 拥塞控制：根据网络状况调整码率

**网络优化**：
- CDN 加速：使用 CDN 分发信令服务器
- 边缘节点：SFU 服务器部署在边缘节点
- 带宽预留：为媒体流预留足够的带宽

### 6.3 架构优化

**自动切换架构**：
```typescript
class RTCClient {
  private async determineArchitecture(roomId: string): Promise<'mesh' | 'sfu'> {
    const roomInfo = await this.getRoomInfo(roomId);
    const userCount = roomInfo.users.length;

    // 根据房间人数自动选择架构
    if (userCount <= 5) {
      return 'mesh'; // 小规模使用 Mesh
    } else if (userCount <= 20) {
      // 根据客户端性能选择
      const clientPerformance = await this.measureClientPerformance();
      return clientPerformance.good ? 'mesh' : 'sfu';
    } else {
      return 'sfu'; // 大规模使用 SFU
    }
  }
}
```

**渐进式升级**：
- 小规模（< 5 人）：Mesh 架构
- 中规模（5-20 人）：根据客户端性能选择
- 大规模（> 20 人）：强制使用 SFU

---

## 七、实施建议

### 7.1 短期方案（1-2 个月）

1. **保持现有 Mesh 架构**
2. **添加 SFU 客户端支持**：支持连接外部 SFU 服务器（Mediasoup/Janus）
3. **优化现有实现**：连接池、批量消息、网络质量监控

### 7.2 中期方案（3-6 个月）

1. **集成 Mediasoup**：提供统一的 API，自动选择架构
2. **实现自动切换**：根据房间人数和客户端性能自动选择架构
3. **性能监控**：添加详细的性能指标和监控

### 7.3 长期方案（6-12 个月）

1. **自研 SFU 实现**：使用 WebAssembly 或 FFI 实现 SFU 服务器
2. **完整解决方案**：提供从信令到媒体的完整解决方案
3. **云服务支持**：提供云端的 SFU 服务

---

## 八、性能对比表

| 指标 | Mesh 架构 | SFU 架构 | MCU 架构 |
|------|----------|---------|---------|
| **单个房间最大人数** | 10-20 人 | 100-1,000+ 人 | 20-100 人 |
| **服务器总并发用户数** | 5,000-10,000 人 | 1,000-5,000 人 | 100-500 人 |
| **客户端连接数** | (N-1) 个 | 1 个 | 1 个 |
| **客户端上行带宽** | 1x | 1x | 1x |
| **客户端下行带宽** | (N-1)x | 可控制（订阅） | 1x（混合流） |
| **服务器 CPU** | 低（只处理信令） | 中（RTP 转发） | 高（解码+混合+编码） |
| **服务器内存** | 低（每个连接 10-20 KB） | 中（每个连接 5-10 MB） | 高（每个连接 50-100 MB） |
| **服务器带宽** | 低（只处理信令） | 高（转发媒体流） | 中（接收+发送混合流） |
| **延迟** | 最低（P2P 直连） | 低（增加一跳，10-50ms） | 中（混合延迟，30-150ms） |
| **灵活性** | 低（必须接收所有流） | 高（可以选择性订阅） | 低（只能接收混合流） |
| **实现复杂度** | 低 | 中 | 高 |
| **适用场景** | 小规模房间 | 大规模房间 | 广播型会议 |
| **是否需要媒体服务器** | ❌ 不需要 | ✅ 需要 | ✅ 需要 |

### 8.1 容量对比详细表

**单个房间容量**：

| 房间人数 | Mesh | SFU | MCU |
|---------|------|-----|-----|
| 2-5 人 | ✅ 最佳 | ✅ 可行 | ✅ 可行 |
| 10 人 | ✅ 可行 | ✅ 最佳 | ✅ 可行 |
| 20 人 | ⚠️ 勉强 | ✅ 最佳 | ✅ 可行 |
| 50 人 | ❌ 不可行 | ✅ 最佳 | ⚠️ 需要高配 |
| 100 人 | ❌ 不可行 | ✅ 最佳 | ⚠️ 需要 GPU |
| 500 人 | ❌ 不可行 | ✅ 可行（需要高配） | ❌ 不可行 |
| 1,000 人 | ❌ 不可行 | ✅ 可行（需要集群） | ❌ 不可行 |

**服务器总容量**（支持的总用户数）：

| 架构 | 单机容量 | 集群容量 | 说明 |
|------|---------|---------|------|
| **Mesh** | 5,000-10,000 人 | 50,000+ 人 | 信令服务器，负载低 |
| **SFU** | 1,000-2,000 人 | 10,000+ 人 | 媒体服务器，负载中等 |
| **MCU** | 100-200 人 | 1,000+ 人 | 媒体服务器，负载高 |

---

## 九、总结

### 9.1 当前状态

- ✅ **Mesh 架构**：已实现，适合小规模（< 10 人）
- ✅ **信令服务器**：性能良好，可支持数千个连接
- ❌ **SFU/MCU**：未实现，需要配合外部媒体服务器

### 9.2 升级建议

1. **短期**：添加 SFU 客户端支持，集成现有媒体服务器
2. **中期**：实现自动架构切换，优化性能
3. **长期**：考虑自研 SFU 实现

### 9.3 服务器配置建议

- **小规模（< 10 人）**：单机部署，使用 Mesh 架构
- **中规模（10-100 人）**：信令服务器 + SFU 服务器（Mediasoup/Janus）
- **大规模（100+ 人）**：集群部署，信令服务器集群 + SFU 服务器集群

---

**文档版本**：1.0.0
**最后更新**：2026-01-18
**作者**：Dreamer Team
